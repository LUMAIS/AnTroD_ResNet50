{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install matplotlib scikit-learn pytorch-lightning"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!unzip ImageLibrary_6_11_19.zip"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import os\r\n",
    "from typing import (\r\n",
    "    List, Any, Callable, \r\n",
    "    Optional, Tuple, Union, Dict)\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "import pytorch_lightning as pl\r\n",
    "from pytorch_lightning.callbacks import EarlyStopping\r\n",
    "from sklearn.metrics import precision_recall_fscore_support\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "import torchvision.models as models\r\n",
    "from torchvision import transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "np.random.seed(42)\r\n",
    "\r\n",
    "data_path = './ImageLibrary_6_11_19'\r\n",
    "\r\n",
    "training_fraction = 0.7\r\n",
    "validation_fraction = 0.2\r\n",
    "test_fraction = 0.1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main classes and helper functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "class ImageFilelistDataset(torch.utils.data.Dataset):\r\n",
    "    def __init__(self, \r\n",
    "            image_paths: List[str], \r\n",
    "            labels: List[int],\r\n",
    "            transform: Optional[Callable] = None,\r\n",
    "            test: bool = False\r\n",
    "        ):\r\n",
    "        self.img_paths = image_paths\r\n",
    "        self.labels = labels\r\n",
    "        self.transform = transform or transforms.ToTensor()\r\n",
    "        self.test = test\r\n",
    "\r\n",
    "    def _loader(self, path: str) -> Any:\r\n",
    "        return Image.open(path).convert('RGB')\r\n",
    "\r\n",
    "    def __getitem__(self, index: int) -> Union[torch.Tensor, Tuple[torch.Tensor, int]]:\r\n",
    "        img_path = self.img_paths[index]\r\n",
    "        img_rgb = self._loader(img_path)\r\n",
    "        img = self.transform(img_rgb)\r\n",
    "        img_rgb.close()\r\n",
    "\r\n",
    "        if self.test:\r\n",
    "            return img\r\n",
    "\r\n",
    "        target = self.labels[index]\r\n",
    "        return img, target\r\n",
    "\r\n",
    "    def __len__(self) -> int:\r\n",
    "        return len(self.img_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "class ImageDataModule(pl.LightningDataModule):\r\n",
    "    def __init__(\r\n",
    "            self, \r\n",
    "            data_path: str, \r\n",
    "            batch_size: int = 32, \r\n",
    "            img_transforms: Optional[Callable] = None\r\n",
    "        ):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.data_path = data_path\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.transforms = img_transforms\r\n",
    "    \r\n",
    "    def _load_paths(self) -> Tuple[List[str], List[int]]:\r\n",
    "        \"\"\"\r\n",
    "        Finds paths of images of each class \r\n",
    "        and randomly selects the same number of images of each class.\r\n",
    "        Thus, the number of samples of each class is the same.\r\n",
    "        Returns a list with image paths and a list of class labels.\r\n",
    "        \"\"\"\r\n",
    "        class_dirs = os.listdir(self.data_path)\r\n",
    "\r\n",
    "        min_class_imgs_count = min([\r\n",
    "            len(os.listdir(os.path.join(data_path, class_dir))) \r\n",
    "            for class_dir in class_dirs\r\n",
    "        ])\r\n",
    "\r\n",
    "        data_paths = []\r\n",
    "        classes = []\r\n",
    "\r\n",
    "        for i, class_dir in enumerate(class_dirs):\r\n",
    "            class_files = os.listdir(os.path.join(data_path, class_dir))\r\n",
    "            class_files_random = np.random.choice(\r\n",
    "                class_files, \r\n",
    "                size=min_class_imgs_count, \r\n",
    "                replace=False\r\n",
    "            )\r\n",
    "            data_paths.extend([\r\n",
    "                os.path.join(data_path, class_dir, class_file)\r\n",
    "                for class_file in class_files_random\r\n",
    "            ])\r\n",
    "            classes.extend([i]*min_class_imgs_count) \r\n",
    "        return data_paths, classes\r\n",
    "    \r\n",
    "    def _data_split(self, data_paths: List[str], classes: List[int]):\r\n",
    "        self.X_train, X_rem, self.y_train, y_rem = train_test_split(\r\n",
    "            data_paths, classes, \r\n",
    "            test_size=validation_fraction + test_fraction, \r\n",
    "            stratify=classes\r\n",
    "        )\r\n",
    "        self.X_val, self.X_test, self.y_val, self.y_test = train_test_split(\r\n",
    "            X_rem, y_rem, \r\n",
    "            test_size=test_fraction / (validation_fraction+test_fraction), \r\n",
    "            stratify=y_rem\r\n",
    "        )\r\n",
    "\r\n",
    "    def setup(self, stage: Optional[str] = None):\r\n",
    "        data_paths, classes = self._load_paths()\r\n",
    "        self._data_split(data_paths, classes)\r\n",
    "\r\n",
    "    def train_dataloader(self):\r\n",
    "        data = ImageFilelistDataset(\r\n",
    "            self.X_train, self.y_train, transform=self.transforms['train'])\r\n",
    "        return torch.utils.data.DataLoader(\r\n",
    "            dataset=data,\r\n",
    "            batch_size=self.batch_size,\r\n",
    "            shuffle=True,\r\n",
    "            num_workers=8\r\n",
    "        )\r\n",
    "\r\n",
    "    def val_dataloader(self):\r\n",
    "        data = ImageFilelistDataset(\r\n",
    "            self.X_val, self.y_val, transform=self.transforms['default'])\r\n",
    "        return torch.utils.data.DataLoader(\r\n",
    "            dataset=data,\r\n",
    "            batch_size=self.batch_size,\r\n",
    "            num_workers=8\r\n",
    "        )\r\n",
    "\r\n",
    "    def test_dataloader(self):\r\n",
    "        data = ImageFilelistDataset(\r\n",
    "            self.X_test, self.y_test, transform=self.transforms['default'])\r\n",
    "        return torch.utils.data.DataLoader(\r\n",
    "            dataset=data,\r\n",
    "            batch_size=self.batch_size,\r\n",
    "            num_workers=8\r\n",
    "        )\r\n",
    "\r\n",
    "    def predict_dataloader(self):\r\n",
    "        data = ImageFilelistDataset(\r\n",
    "            self.X_test, self.y_test, transform=self.transforms['default'], test=True)\r\n",
    "        return torch.utils.data.DataLoader(\r\n",
    "            dataset=data,\r\n",
    "            num_workers=8\r\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "class ResNet50(pl.LightningModule):\r\n",
    "    def __init__(self, num_target_classes: int):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.model = self._build_model(num_target_classes)\r\n",
    "        self.num_target_classes = num_target_classes\r\n",
    "\r\n",
    "        self.loss = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "    def _build_model(self, num_classes: int) -> models.resnet.ResNet:\r\n",
    "        model = models.resnet50(pretrained=True)\r\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\r\n",
    "        return model\r\n",
    "    \r\n",
    "    def _log_metric(self, metric: str, value: float):\r\n",
    "        self.log(metric, value, prog_bar=True, on_epoch=True, on_step=False)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.model(x)\r\n",
    "    \r\n",
    "    def training_step(self, batch, batch_idx: int): \r\n",
    "        loss, acc = self._step(batch)\r\n",
    "        self._log_metric(\"train_loss\", loss)\r\n",
    "        self._log_metric(\"train_acc\", acc)      \r\n",
    "        return loss\r\n",
    "\r\n",
    "    def validation_step(self, batch, batch_idx: int): \r\n",
    "        loss, acc = self._step(batch)\r\n",
    "        self._log_metric(\"val_loss\", loss)\r\n",
    "        self._log_metric(\"val_acc\", acc)    \r\n",
    "\r\n",
    "    def test_step(self, batch, batch_idx: int): \r\n",
    "        loss, acc = self._step(batch)\r\n",
    "        self._log_metric(\"test_loss\", loss)\r\n",
    "        self._log_metric(\"test_acc\", acc)               \r\n",
    "    \r\n",
    "    def _step(self, batch):\r\n",
    "        x, y = batch\r\n",
    "        y_pred = self.forward(x)\r\n",
    "        acc = self.acc(y_pred, y)\r\n",
    "        loss = self.loss(y_pred, y)\r\n",
    "        return loss, acc\r\n",
    "\r\n",
    "    def acc(self, y_pred, y_target):\r\n",
    "        return (y_target == torch.argmax(y_pred, 1)).type(torch.FloatTensor).mean()\r\n",
    "\r\n",
    "    def configure_optimizers(self):\r\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "def get_binary_metrics(\r\n",
    "        y_true: List[int], \r\n",
    "        y_pred: List[torch.Tensor], \r\n",
    "        target_class: int = 3) -> Dict[str, float]:\r\n",
    "    \"\"\"\r\n",
    "    Converts the results to a binary form according to `target_class`. \r\n",
    "    Calculates the precision, recall and F1 score.\r\n",
    "    \"\"\"\r\n",
    "    y_true = np.array(y_true)\r\n",
    "    y_true[y_true != target_class] = 0\r\n",
    "    y_true[y_true == target_class] = 1\r\n",
    "\r\n",
    "    y_pred = [v[0] for v in y_pred]\r\n",
    "    y_pred = torch.argmax(torch.stack(y_pred), dim=1)\r\n",
    "    y_pred[y_pred != target_class] = 0\r\n",
    "    y_pred[y_pred == target_class] = 1\r\n",
    "\r\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\r\n",
    "        y_true, y_pred.cpu(), average='binary')\r\n",
    "    return {\r\n",
    "        \"precision\": precision,\r\n",
    "        \"recall\": recall,\r\n",
    "        \"f1_score\": f1\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "img_transforms = {\r\n",
    "    'train': transforms.Compose([\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.RandomAffine(\r\n",
    "            degrees=(-180, 180), \r\n",
    "            translate=(0.228, 0.228) # Translate in pixels is 175*0.228 = 39.9 px\r\n",
    "        ),\r\n",
    "        transforms.RandomVerticalFlip(),\r\n",
    "        transforms.RandomHorizontalFlip(),\r\n",
    "        transforms.Resize((224, 224))\r\n",
    "    ]),\r\n",
    "    'default': transforms.Compose([\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Resize((224, 224))\r\n",
    "    ])\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "data_module = ImageDataModule(data_path, img_transforms=img_transforms)\r\n",
    "data_module.setup()\r\n",
    "num_target_classes = len(os.listdir(data_path))\r\n",
    "target_class = os.listdir(data_path).index('trophallaxis')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "model = ResNet50(num_target_classes)\r\n",
    "trainer = pl.Trainer(\r\n",
    "    gpus=1, max_epochs=20, \r\n",
    "    callbacks=[EarlyStopping('val_loss', patience=5)]\r\n",
    ")\r\n",
    "trainer.fit(model, data_module)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | ResNet           | 23.5 M\n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.065    Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110afb69e09b4188970024850f54193d",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Result metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train loss and accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "trainer.validate(model, data_module.train_dataloader())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.9464057683944702, 'val_loss': 0.1531306803226471}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'val_loss': 0.1531306803226471, 'val_acc': 0.9464057683944702}]"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation loss and accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "trainer.validate(model, data_module.val_dataloader())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.913690447807312, 'val_loss': 0.22848735749721527}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'val_loss': 0.22848735749721527, 'val_acc': 0.913690447807312}]"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test loss and accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "trainer.validate(model, data_module.test_dataloader())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.9317507147789001, 'val_loss': 0.23040859401226044}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'val_loss': 0.23040859401226044, 'val_acc': 0.9317507147789001}]"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test binary classification metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "y_pred = trainer.predict(model, data_module.predict_dataloader())\r\n",
    "get_binary_metrics(data_module.y_test, y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Predicting: 74it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b55d9bfab147b4a974beb85f8d4f07",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'precision': 1.0, 'recall': 0.9285714285714286, 'f1_score': 0.962962962962963}"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "torch.save(model.model, 'resnet50.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "trainer.save_checkpoint('resnet50.ckpt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check models loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "loaded_model = torch.load('resnet50.pt')\r\n",
    "loaded_model.eval()\r\n",
    "\r\n",
    "new_model = ResNet50(num_target_classes)\r\n",
    "new_model.model = loaded_model\r\n",
    "\r\n",
    "y_pred = trainer.predict(new_model, data_module.predict_dataloader())\r\n",
    "get_binary_metrics(data_module.y_test, y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Predicting: 74it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7bff0616104baa84de12a4c01b6fcd",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'precision': 1.0, 'recall': 0.9285714285714286, 'f1_score': 0.962962962962963}"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "loaded_model = ResNet50.load_from_checkpoint('resnet50.ckpt', num_target_classes=num_target_classes)\r\n",
    "y_pred = trainer.predict(loaded_model, data_module.predict_dataloader())\r\n",
    "get_binary_metrics(data_module.y_test, y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Predicting: 74it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671902c0597d4287a7dfe24aa5a3be12",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'precision': 1.0, 'recall': 0.9285714285714286, 'f1_score': 0.962962962962963}"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary metrics for the whole dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "full_data = data_module.X_train + data_module.X_val + data_module.X_test\r\n",
    "full_target = data_module.y_train + data_module.y_val + data_module.y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "data = ImageFilelistDataset(full_data, full_target, transform=img_transforms['default'], test=True)\r\n",
    "full_dataloader = torch.utils.data.DataLoader(\r\n",
    "    dataset=data,\r\n",
    "    num_workers=8\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "y_pred = trainer.predict(model, full_dataloader)\r\n",
    "get_binary_metrics(full_target, y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Predicting: 74it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6797b46fac4ee58a85100f9dfb7319",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'precision': 0.9987029831387808,\n",
       " 'recall': 0.9166666666666666,\n",
       " 'f1_score': 0.9559279950341403}"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65bd7c2764f2dff60b4a34f3c64d1d578d3bb300e94010be7ba085a18a8fb15a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('pytorch_env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}